# ============================================================================
# backend/app/services/llm_client.py - Google Gemini API Client
# ============================================================================
# AÃ§Ä±klama:
#   Google Generative AI (Gemini) API'sini kullanarak sohbet cevaplarÄ±
#   oluÅŸturur. Intent sÄ±nÄ±flandÄ±rmasÄ± baÅŸarÄ±sÄ±z olduÄŸunda fallback olarak
#   Ã§alÄ±ÅŸÄ±r. Model seÃ§imi dinamik ve API key tabanlÄ±dÄ±r.
#
#   Supported Models:
#     - gemini-1.5-flash (hÄ±zlÄ±, dÃ¼ÅŸÃ¼k cost)
#     - gemini-1.5-pro (daha gÃ¼Ã§lÃ¼)
#     - gemini-2.0-flash (en yeni)
# ============================================================================

import os
from typing import Optional
from dotenv import load_dotenv
import logging

import google.generativeai as genai


# ============================================================================
# LOGGING & CONFIGURATION
# ============================================================================

logger: logging.Logger = logging.getLogger(__name__)

# Environment variables'dan API key'i yÃ¼kle
load_dotenv()
GOOGLE_API_KEY: Optional[str] = os.getenv("GOOGLE_API_KEY")

# Sistem prompt (bot kimliÄŸi)
SYSTEM_PROMPT: str = """
Sen Artvin Ã‡oruh Ãœniversitesi (AÃ‡Ãœ) asistanÄ±sÄ±n.
KullanÄ±cÄ±larÄ±n akademik, idari ve kampÃ¼s-ilgili sorularÄ±na cevap verirsin.
Samimi, yardÄ±msever ve kÄ±sa cevaplar ver.
EÄŸer sorunun konu dÄ±ÅŸÄ± ise nazikÃ§e konuya dÃ¶ndÃ¼rmeye Ã§alÄ±ÅŸ.
"""


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def _validate_api_key() -> bool:
    """
    API key'in mevcut ve geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol et.

    Returns:
        bool: API key mevcutsa True, yoksa False
    """
    if not GOOGLE_API_KEY:
        logger.error("âŒ GOOGLE_API_KEY environment variable'Ä± eksik!")
        return False
    return True


def _find_available_model() -> Optional[str]:
    """
    Gemini API'den mevcut olan ve generateContent destekleyen modeli bul.

    Preference Order:
      1. gemini-*-flash (hÄ±zlÄ±, dÃ¼ÅŸÃ¼k maliyet)
      2. gemini-*-pro (daha gÃ¼Ã§lÃ¼)
      3. Herhangi bir gemini modeli

    Returns:
        str | None: Model adÄ± veya None (model bulunamadÄ±)

    Error Handling:
      - API hatasÄ± olursa: varsayÄ±lan model (gemini-1.5-flash) dÃ¶ndÃ¼r
    """
    try:
        logger.info("ğŸ” Mevcut Gemini modelleri aranÄ±yor...")

        # API'den modelleri listele
        available_models: list = list(genai.list_models())

        # generateContent destekleyen gemini modellerini filtrele
        gemini_models: list = [
            m for m in available_models
            if 'generateContent' in m.supported_generation_methods
            and 'gemini' in m.name
        ]

        if not gemini_models:
            logger.warning("âš ï¸  Mevcut Gemini modeli bulunamadÄ±!")
            return None

        # Flash modelini tercih et (daha hÄ±zlÄ± ve daha ucuz)
        for model in gemini_models:
            if 'flash' in model.name:
                logger.info(f"âœ… SeÃ§ilen model: {model.name}")
                return model.name

        # Flash yoksa pro'yu dene
        for model in gemini_models:
            if 'pro' in model.name:
                logger.info(f"âœ… SeÃ§ilen model: {model.name}")
                return model.name

        # Yoksa herhangi bir Gemini modeli seÃ§
        logger.info(f"âœ… SeÃ§ilen model: {gemini_models[0].name}")
        return gemini_models[0].name

    except Exception as e:
        logger.error(f"âŒ Model listeleme hatasÄ±: {e}")
        logger.info("âš ï¸  VarsayÄ±lan model (gemini-1.5-flash) kullanÄ±lÄ±yor...")
        return "models/gemini-1.5-flash"


# ============================================================================
# MAIN LLM FUNCTION
# ============================================================================

def get_llm_response(user_message: str) -> str:
    """
    KullanÄ±cÄ± mesajÄ±nÄ± Google Gemini'ye gÃ¶nder ve cevap al.

    Process:
      1. API key kontrol et
      2. Gemini API'yi ayarla
      3. Uygun modeli bul
      4. Sistemsel talimatlarÄ± (system prompt) ekle
      5. Cevap oluÅŸtur

    Args:
        user_message (str): KullanÄ±cÄ± tarafÄ±ndan yazÄ±lan mesaj

    Returns:
        str: Gemini tarafÄ±ndan Ã¼retilen cevap veya error message

    Error Handling:
      - API key eksik â†’ Error message dÃ¶ndÃ¼r
      - Model bulunamadÄ± â†’ Error message dÃ¶ndÃ¼r
      - API call hatasÄ± â†’ Error message dÃ¶ndÃ¼r
    """
    # -------- ADIM 1: API KEY KONTROL --------
    if not _validate_api_key():
        return (
            "âš™ï¸  Sistem yapÄ±landÄ±rma hatasÄ±: API anahtarÄ± eksik. "
            "LÃ¼tfen yÃ¶neticiye baÅŸvurun."
        )

    try:
        # -------- ADIM 2: API AYARLA --------
        genai.configure(api_key=GOOGLE_API_KEY)

        # -------- ADIM 3: MODELI BUL --------
        target_model_name: Optional[str] = _find_available_model()

        if not target_model_name:
            logger.error("âŒ Uygun Gemini modeli bulunamadÄ±.")
            return (
                "Maalesef ÅŸu anda AI servisine eriÅŸilemiyor. "
                "LÃ¼tfen daha sonra tekrar deneyin."
            )

        logger.info(f"ğŸ“Š KullanÄ±lan Model: {target_model_name}")

        # -------- ADIM 4: MODELÄ° BAÅLAT --------
        model: any = genai.GenerativeModel(target_model_name)

        # -------- ADIM 5: CEVAP OLUÅTUR --------
        full_prompt: str = (
            f"{SYSTEM_PROMPT}\n\n"
            f"KullanÄ±cÄ±: {user_message}\n"
            f"Asistan:"
        )

        response: any = model.generate_content(full_prompt)
        response_text: str = response.text.strip()

        logger.info(f"âœ… LLM cevabÄ± oluÅŸturuldu ({len(response_text)} karakter)")
        return response_text

    except Exception as e:
        logger.error(f"âŒ LLM HatasÄ±: {str(e)}")
        return (
            f"ÃœzgÃ¼nÃ¼m, ÅŸu anda AI servisine baÄŸlanamÄ±yorum. "
            f"Hata: {str(e)[:50]}..."
        )